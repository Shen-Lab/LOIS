{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to LOIS's doumentation! Overview This is the documentation for LOIS : Learning to Optimize in Swarms. LOIS is a 'Learning to Optimize' framework with swarm intelligence and posterior estimation to automatically design optimizers for various objective functions. If you find this documention is useful, please cite our paper . Content Overview Motivation Installation Add your function Training Evaluation","title":"Overview"},{"location":"#welcome-to-loiss-doumentation","text":"","title":"Welcome to LOIS's doumentation!"},{"location":"#overview","text":"This is the documentation for LOIS : Learning to Optimize in Swarms. LOIS is a 'Learning to Optimize' framework with swarm intelligence and posterior estimation to automatically design optimizers for various objective functions. If you find this documention is useful, please cite our paper .","title":"Overview"},{"location":"#content","text":"Overview Motivation Installation Add your function Training Evaluation","title":"Content"},{"location":"about/","text":"Ratus at aequora nulli Interea vilibus qui radiis ille sumere Phoronide Lorem markdownum caedisque et veluti vale tenuis pastoris porrigis virgineusque hospes tremulo in satis inpubesque nunc vigiles. Veris clarique anhelitus iuvenali bis est adhuc est, quo memorare quinque altius et ferro ut dederant. if (nanometer(dsl + nat, ccLcd(edi_file * mtu_codec), isdn( jsf_file_barcraft.dataBash(25, 4), checksum_bitrate_ring))) { coreNumberUnix = menu_cisc(1, asp, dvi(4)); fddi_retina = busWindowsFrame; } var memory_facebook_rpm = bounce.androidDialTweet(copy, floodIrc, keyboard); barePngBluetooth = word; A regia regique pariterque sulphure se turba Conterit spectentque imas penetralia quaterque nate relictum volenti genus Lotis abis imago quos. Potentem spatio capillos ipsa luna est haec demersus non! var word = plainCard(add(pathSslSmb), 3, lionMainframe(dock) + reader_network_process); srgbRam += white(archie); if (4 - cleanTerahertz) { olapReal(typeface_alignment + 5); } else { petaflopsOsiFlash.cgiError.file_imap(gate, app_filename_add, 1); } if (piracy + pageSupply(scriptHashtagNetwork)) { clickE(double_autoresponder, pdaPortXml); newsgroupPublishingJre(3 - 2, stickClock.usbError.fragmentationBasic(4, link)); petaflops_bar = capsBrowser(ddr_forum_half); } Certa in saepe pedum et Lacinia Veneri A et tuae terris id, tecta ulmo, regimen foret accipienda et suos considerat exsul. Et hyaenam fessam est solum edidit ave curvos longa vinci. Lacrimas cum: et roboris facinus; aethera via venit? Neque cacumine non Sole casus Pressit Clitorio levis Circe est auras testantur Iuxta texit te periclo ille odiis Clamor causaque relictus Telamonius aegra ter Rhanisque Cur exspectatus vult possumus bello choro adeunt Iani quaeque qua moror pudorem fame, mora mille rigidum at audito aetherium. Alterius redeunt tinctas turbata; est siquis cadit occupat his silvas cornua. Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout asasa[about](./index.md) mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. [about](./about.md)","title":"Ratus at aequora nulli"},{"location":"about/#ratus-at-aequora-nulli","text":"","title":"Ratus at aequora nulli"},{"location":"about/#interea-vilibus-qui-radiis-ille-sumere-phoronide","text":"Lorem markdownum caedisque et veluti vale tenuis pastoris porrigis virgineusque hospes tremulo in satis inpubesque nunc vigiles. Veris clarique anhelitus iuvenali bis est adhuc est, quo memorare quinque altius et ferro ut dederant. if (nanometer(dsl + nat, ccLcd(edi_file * mtu_codec), isdn( jsf_file_barcraft.dataBash(25, 4), checksum_bitrate_ring))) { coreNumberUnix = menu_cisc(1, asp, dvi(4)); fddi_retina = busWindowsFrame; } var memory_facebook_rpm = bounce.androidDialTweet(copy, floodIrc, keyboard); barePngBluetooth = word;","title":"Interea vilibus qui radiis ille sumere Phoronide"},{"location":"about/#a-regia-regique-pariterque-sulphure-se-turba","text":"Conterit spectentque imas penetralia quaterque nate relictum volenti genus Lotis abis imago quos. Potentem spatio capillos ipsa luna est haec demersus non! var word = plainCard(add(pathSslSmb), 3, lionMainframe(dock) + reader_network_process); srgbRam += white(archie); if (4 - cleanTerahertz) { olapReal(typeface_alignment + 5); } else { petaflopsOsiFlash.cgiError.file_imap(gate, app_filename_add, 1); } if (piracy + pageSupply(scriptHashtagNetwork)) { clickE(double_autoresponder, pdaPortXml); newsgroupPublishingJre(3 - 2, stickClock.usbError.fragmentationBasic(4, link)); petaflops_bar = capsBrowser(ddr_forum_half); }","title":"A regia regique pariterque sulphure se turba"},{"location":"about/#certa-in-saepe-pedum-et-lacinia-veneri","text":"A et tuae terris id, tecta ulmo, regimen foret accipienda et suos considerat exsul. Et hyaenam fessam est solum edidit ave curvos longa vinci. Lacrimas cum: et roboris facinus; aethera via venit? Neque cacumine non Sole casus Pressit Clitorio levis Circe est auras testantur Iuxta texit te periclo ille odiis Clamor causaque relictus Telamonius aegra ter Rhanisque Cur exspectatus vult possumus bello choro adeunt Iani quaeque qua moror pudorem fame, mora mille rigidum at audito aetherium. Alterius redeunt tinctas turbata; est siquis cadit occupat his silvas cornua.","title":"Certa in saepe pedum et Lacinia Veneri"},{"location":"about/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"about/#project-layout","text":"asasa[about](./index.md) mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. [about](./about.md)","title":"Project layout"},{"location":"install/","text":"Installation Codes: Download LOIS package through: git clone https://github.com/Shen-Lab/LOIS Dependencies: LOIS are mainly developed in tensorflow v1.13 . For protein docking applications, there are two other denpendencies: Sampling: cNMA Initial Structure Minimization: CHARMM","title":"Installation"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#codes","text":"Download LOIS package through: git clone https://github.com/Shen-Lab/LOIS","title":"Codes:"},{"location":"install/#dependencies","text":"LOIS are mainly developed in tensorflow v1.13 . For protein docking applications, there are two other denpendencies: Sampling: cNMA Initial Structure Minimization: CHARMM","title":"Dependencies:"},{"location":"motivation/","text":"Motivation Why we need Learning to Optimize? Optimization provides a mathematical foundation for solving quantitative problems in many fields, along with numerical challenges. The no free lunch theorem indicates the non-existence of a universally best optimization algorithm for all objectives. To manually design an effective optimization algorithm for a given problem, many efforts have been spent on tuning and validating pipelines, architectures, and hyperparameters. To overcome the laborious manual design, an emerging approach of meta-learning (learning to learn) takes advantage of the knowledge learned from related tasks. In meta-learning, the goal is to learn a meta-learner that could solve a set of problems, where each sample in the training or test set is a particular problem. As in classical machine learning, the fundamental assumption of meta-learning is the generalizability from solving the training problems to solving the test ones. For optimization problems, a key to meta-learning is how to efficiently utilize the information in the objective function and explore the space of optimization algorithms. What are the remaining gaps? The target applications of previous methods are mainly focused on training deep neural networks, except [1] focusing on optimizing black-box functions. There are three limitations of these methods. First, they learn in a limited algorithmic space, namely point-based optimization algorithms that use gradients or not (including SGD and Adam). So far there is no method in learning to learn that reflects population-based algorithms (such as evolutionary and swarm algorithms) proven powerful in many optimization tasks. Second, their learning is guided by a limited meta loss, often the cumulative regret in sampling history that primarily drives exploitation. One exception is the expected improvement (EI) used by [1] under Gaussian processes. Last but not the least, these methods do not interpret the process of learning update formula, despite the previous usage of attention mechanisms in [2]. Why LOIS? To overcome aforementioned limitations of current learning-to-optimize methods, we present a new meta-optimizer with the following contributions: ( Where to learn ): We learn in an extended space of both point-based and population-based optimization algorithms. ( How to learn ): We incorporate the posterior into meta-loss to guide the search in the algorithmic space and balance the exploitation-exploration trade-off. ( What more to learn ): We design a novel architecture where a population of LSTMs jointly learn iterative update formula for a population of samples and embedded sample- and feature-level attentions to explain the formula References [1] Yutian Chen, Matthew W Hoffman, Sergio G\u00f3mez Colmenarejo, Misha Denil, Timothy P Lillicrap, Matt Botvinick, and Nando de Freitas. Learning to learn without gradient descent by gradient descent. In Proceedings of the 34th International Conference on Machine Learning Volume 70 , pages 748\u2013756. JMLR. org, 2017. [2] Olga Wichrowska, Niru Maheswaranathan, Matthew W Hoffman, Sergio Gomez Colmenarejo, Misha Denil, Nando de Freitas, and Jascha Sohl-Dickstein. Learned optimizers that scale and generalize. In Proceedings of the 34th International Conference on Machine Learning Volume 70 , pages 3751\u20133760. JMLR. org, 2017.","title":"Motivation"},{"location":"motivation/#motivation","text":"","title":"Motivation"},{"location":"motivation/#why-we-need-learning-to-optimize","text":"Optimization provides a mathematical foundation for solving quantitative problems in many fields, along with numerical challenges. The no free lunch theorem indicates the non-existence of a universally best optimization algorithm for all objectives. To manually design an effective optimization algorithm for a given problem, many efforts have been spent on tuning and validating pipelines, architectures, and hyperparameters. To overcome the laborious manual design, an emerging approach of meta-learning (learning to learn) takes advantage of the knowledge learned from related tasks. In meta-learning, the goal is to learn a meta-learner that could solve a set of problems, where each sample in the training or test set is a particular problem. As in classical machine learning, the fundamental assumption of meta-learning is the generalizability from solving the training problems to solving the test ones. For optimization problems, a key to meta-learning is how to efficiently utilize the information in the objective function and explore the space of optimization algorithms.","title":"Why we need Learning to Optimize?"},{"location":"motivation/#what-are-the-remaining-gaps","text":"The target applications of previous methods are mainly focused on training deep neural networks, except [1] focusing on optimizing black-box functions. There are three limitations of these methods. First, they learn in a limited algorithmic space, namely point-based optimization algorithms that use gradients or not (including SGD and Adam). So far there is no method in learning to learn that reflects population-based algorithms (such as evolutionary and swarm algorithms) proven powerful in many optimization tasks. Second, their learning is guided by a limited meta loss, often the cumulative regret in sampling history that primarily drives exploitation. One exception is the expected improvement (EI) used by [1] under Gaussian processes. Last but not the least, these methods do not interpret the process of learning update formula, despite the previous usage of attention mechanisms in [2].","title":"What are the remaining gaps?"},{"location":"motivation/#why-lois","text":"To overcome aforementioned limitations of current learning-to-optimize methods, we present a new meta-optimizer with the following contributions: ( Where to learn ): We learn in an extended space of both point-based and population-based optimization algorithms. ( How to learn ): We incorporate the posterior into meta-loss to guide the search in the algorithmic space and balance the exploitation-exploration trade-off. ( What more to learn ): We design a novel architecture where a population of LSTMs jointly learn iterative update formula for a population of samples and embedded sample- and feature-level attentions to explain the formula","title":"Why LOIS?"},{"location":"motivation/#references","text":"[1] Yutian Chen, Matthew W Hoffman, Sergio G\u00f3mez Colmenarejo, Misha Denil, Timothy P Lillicrap, Matt Botvinick, and Nando de Freitas. Learning to learn without gradient descent by gradient descent. In Proceedings of the 34th International Conference on Machine Learning Volume 70 , pages 748\u2013756. JMLR. org, 2017. [2] Olga Wichrowska, Niru Maheswaranathan, Matthew W Hoffman, Sergio Gomez Colmenarejo, Misha Denil, Nando de Freitas, and Jascha Sohl-Dickstein. Learned optimizers that scale and generalize. In Proceedings of the 34th International Conference on Machine Learning Volume 70 , pages 3751\u20133760. JMLR. org, 2017.","title":"References"},{"location":"dev_docs/eval/","text":"evaluate.py The main function for evaluating in LOIS. python evaluate.py --problem=$problem_name --optimizer=L2L --path=$path_to_the_saved_model Arugments: problem : The name of the optimization problem for evaluation. optimizer : The optimizer used for optimizing the problem. For LOIS, set it equal = L2L. path : The path to the trained model.","title":"evaluate.py"},{"location":"dev_docs/eval/#evaluatepy","text":"The main function for evaluating in LOIS. python evaluate.py --problem=$problem_name --optimizer=L2L --path=$path_to_the_saved_model Arugments: problem : The name of the optimization problem for evaluation. optimizer : The optimizer used for optimizing the problem. For LOIS, set it equal = L2L. path : The path to the trained model.","title":"evaluate.py"},{"location":"dev_docs/meta/","text":"meta.py The main function for defining the meta-optimizer computational graph and set up meta-training pipeline. Functions: _nested_assign(ref, value) Returns a nested collection of TensorFlow assign operations. Arguments: ref : Nested collection of TensorFlow variables. value : Values to be assigned to the variables. Must have the same structure as ref . _nested_variable(init, name=None, trainable=False) Returns a nested collection of TensorFlow variables. Arguments: init : Nested collection of TensorFlow initializers. name : Variable name. trainable : Make variables trainable ( False by default). _wrap_variable_creation(func, custom_getter) Provides a custom getter for all variable creations. _get_variables(func) : Calls func, returning any variables created, but ignoring its return value. Arguments: func : Function to be called. Return: A tuple (variables, constants) where the first element is a list of trainable variables and the second is the non-trainable variables. _make_with_custom_variables(func, variables) : Calls func and replaces any trainable variables. _make_nets(variables, config, net_assignments): : Creates the optimizer networks. Arguments: variables : A list of variables to be optimized. config : A dictionary of network configurations, each of which will be passed to networks.Factory to construct a single optimizer net. net_assignments : A list of tuples where each tuple is of the form (netid, variable_names) and is used to assign variables to networks. netid must be a key in config. Return: A tuple (nets, keys, subsets) where nets is a dictionary of created optimizer nets such that the net with key keys[i] should be applied to the subset of variables listed in subsets[i]. Classes: class MetaOptimizer(object): Learning to learn (meta) optimizer. Optimizer which has an internal RNN which takes as input, at each iteration, the gradient of the function being minimized and returns a step direction. This optimizer can then itself be optimized to learn optimization on a set of tasks. Attributes: meta_loss(self,make_loss,len_unroll,net_assignments=None,model_path = None,second_derivatives=False) Arguments: make_loss : Callable which returns the optimizee loss; note that this should create its ops in the default graph. len_unroll : Number of steps to unroll. net_assignments : variable to optimizer mapping. If not None, it should be a list of (k, names) tuples, where k is a valid key in the kwargs passed at at construction time and names is a list of variable names. second_derivatives: Use second derivatives (default is false). Return: loss : The tensor for the meta loss. update : The variable for updating optimization trajectory. reset : The variable for reset optimizee. fx_final : The variable for final objective function value. x_final : The variable for final decision variable value. sub_constants : The variabler for optimizee constants. meta_minimize(self, make_loss, len_unroll, learning_rate=0.01, **kwargs) Returns an operator minimizing the meta-loss Arguments: make_loss : Callable which returns the optimizee loss; note that this should create its ops in the default graph. len_unroll : Number of steps to unroll. learning_rate : Learning rate for the Adam optimizer. **kwargs: keyword arguments forwarded to meta_loss. Return: namedtuple containing ( step , update , reset , fx , x )","title":"meta.py"},{"location":"dev_docs/meta/#metapy","text":"The main function for defining the meta-optimizer computational graph and set up meta-training pipeline.","title":"meta.py"},{"location":"dev_docs/meta/#functions","text":"_nested_assign(ref, value) Returns a nested collection of TensorFlow assign operations. Arguments: ref : Nested collection of TensorFlow variables. value : Values to be assigned to the variables. Must have the same structure as ref . _nested_variable(init, name=None, trainable=False) Returns a nested collection of TensorFlow variables. Arguments: init : Nested collection of TensorFlow initializers. name : Variable name. trainable : Make variables trainable ( False by default). _wrap_variable_creation(func, custom_getter) Provides a custom getter for all variable creations. _get_variables(func) : Calls func, returning any variables created, but ignoring its return value. Arguments: func : Function to be called. Return: A tuple (variables, constants) where the first element is a list of trainable variables and the second is the non-trainable variables. _make_with_custom_variables(func, variables) : Calls func and replaces any trainable variables. _make_nets(variables, config, net_assignments): : Creates the optimizer networks. Arguments: variables : A list of variables to be optimized. config : A dictionary of network configurations, each of which will be passed to networks.Factory to construct a single optimizer net. net_assignments : A list of tuples where each tuple is of the form (netid, variable_names) and is used to assign variables to networks. netid must be a key in config. Return: A tuple (nets, keys, subsets) where nets is a dictionary of created optimizer nets such that the net with key keys[i] should be applied to the subset of variables listed in subsets[i].","title":"Functions:"},{"location":"dev_docs/meta/#classes","text":"class MetaOptimizer(object): Learning to learn (meta) optimizer. Optimizer which has an internal RNN which takes as input, at each iteration, the gradient of the function being minimized and returns a step direction. This optimizer can then itself be optimized to learn optimization on a set of tasks. Attributes: meta_loss(self,make_loss,len_unroll,net_assignments=None,model_path = None,second_derivatives=False) Arguments: make_loss : Callable which returns the optimizee loss; note that this should create its ops in the default graph. len_unroll : Number of steps to unroll. net_assignments : variable to optimizer mapping. If not None, it should be a list of (k, names) tuples, where k is a valid key in the kwargs passed at at construction time and names is a list of variable names. second_derivatives: Use second derivatives (default is false). Return: loss : The tensor for the meta loss. update : The variable for updating optimization trajectory. reset : The variable for reset optimizee. fx_final : The variable for final objective function value. x_final : The variable for final decision variable value. sub_constants : The variabler for optimizee constants. meta_minimize(self, make_loss, len_unroll, learning_rate=0.01, **kwargs) Returns an operator minimizing the meta-loss Arguments: make_loss : Callable which returns the optimizee loss; note that this should create its ops in the default graph. len_unroll : Number of steps to unroll. learning_rate : Learning rate for the Adam optimizer. **kwargs: keyword arguments forwarded to meta_loss. Return: namedtuple containing ( step , update , reset , fx , x )","title":"Classes:"},{"location":"dev_docs/network/","text":"network.py The main function for defining the optimizer network. class StandardDeepLSTM(Network) Standard LSTM layers with a Linear layer on top. Arguments : output_size : Output sizes of the final linear layer. layers : Output sizes of LSTM layers. preprocess_name : Gradient preprocessing class name (in l2l.preprocess or tf modules). Default is tf.identity . preprocess_options : Gradient preprocessing options. scale : Gradient scaling (default is 1.0). initializer : Variable initializer for linear layer. See snt.Linear and snt.LSTM docs for more info. This parameter can be a string (e.g. \"zeros\" will be converted to tf.zeros_initializer). name: Module name. Arributes : _build(self, inputs, prev_state): Connects the StandardDeepLSTM module into the graph. Arguments: inputs : 2D Tensor ([batch_size, input_size]). prev_state : DeepRNN state. Return: Tensor shaped as inputs . class CoordinateWiseDeepLSTM(StandardDeepLSTM) Coordinate-wise LSTM that is used in this study. Arguments : output_size : Output sizes of the final linear layer. layers : Output sizes of LSTM layers. preprocess_name : Gradient preprocessing class name (in l2l.preprocess or tf modules). Default is tf.identity . preprocess_options : Gradient preprocessing options. scale : Gradient scaling (default is 1.0). initializer : Variable initializer for linear layer. See snt.Linear and snt.LSTM docs for more info. This parameter can be a string (e.g. \"zeros\" will be converted to tf.zeros_initializer). name: Module name. Arributes : _build(self, inputs, prev_state): Connects the CoordinateWiseDeepLSTM module into the graph. Arguments: inputs : Arbitrarily shaped Tensor . prev_state : DeepRNN state. Return : Tensor shaped as inputs .","title":"network.py"},{"location":"dev_docs/network/#networkpy","text":"The main function for defining the optimizer network. class StandardDeepLSTM(Network) Standard LSTM layers with a Linear layer on top. Arguments : output_size : Output sizes of the final linear layer. layers : Output sizes of LSTM layers. preprocess_name : Gradient preprocessing class name (in l2l.preprocess or tf modules). Default is tf.identity . preprocess_options : Gradient preprocessing options. scale : Gradient scaling (default is 1.0). initializer : Variable initializer for linear layer. See snt.Linear and snt.LSTM docs for more info. This parameter can be a string (e.g. \"zeros\" will be converted to tf.zeros_initializer). name: Module name. Arributes : _build(self, inputs, prev_state): Connects the StandardDeepLSTM module into the graph. Arguments: inputs : 2D Tensor ([batch_size, input_size]). prev_state : DeepRNN state. Return: Tensor shaped as inputs . class CoordinateWiseDeepLSTM(StandardDeepLSTM) Coordinate-wise LSTM that is used in this study. Arguments : output_size : Output sizes of the final linear layer. layers : Output sizes of LSTM layers. preprocess_name : Gradient preprocessing class name (in l2l.preprocess or tf modules). Default is tf.identity . preprocess_options : Gradient preprocessing options. scale : Gradient scaling (default is 1.0). initializer : Variable initializer for linear layer. See snt.Linear and snt.LSTM docs for more info. This parameter can be a string (e.g. \"zeros\" will be converted to tf.zeros_initializer). name: Module name. Arributes : _build(self, inputs, prev_state): Connects the CoordinateWiseDeepLSTM module into the graph. Arguments: inputs : Arbitrarily shaped Tensor . prev_state : DeepRNN state. Return : Tensor shaped as inputs .","title":"network.py"},{"location":"dev_docs/overview/","text":"We provide an overview of the important files and their relationships. Training : train.py is the main file during training. It will run every epoch, save network parameters. It will call other files one by one that are used for training. Before training : Load optimizer network congifuration : util.py . The train.py will call util.py in order to red optimizer net configuration. Load optimizee problem : util.py -> problems.py . The train.py will call util.py , which will call problems.py in order to load the optimizee problems used for training. Load optimizer network : meta.py . The train.py will use the optimizer net configuration information to build an optimizer in meta.py . optimizer-optimizee graph : meta.py . The meta.py will also build a complete computational graph with both optimizer and optimizee. During training : run every epoch : util.py . This file will run every epoch during training. After training : save meta net parameters : train.py . This file will save the meta net parameters. Evaluation : evaluate.py is the main file during evaluation. It will run a whole evaluation trajectory and save the trajectory. It will call other files one by one that are used for evaluation. Before evaluation : Load optimizer network congifuration : util.py . The evaluate.py will call util.py in order to red optimizer net configuration. Load optimizee problem : util.py -> problems.py . The evaluate.py will call util.py , which will call problems.py in order to load the optimizee problems used for evaluation. Load optimizer network : meta.py . The evaluate.py will use the optimizer net configuration information to build an optimizer in meta.py . optimizer-optimizee graph : meta.py . The meta.py will also build a complete computational graph with both optimizer and optimizee. During evaluation : run the trajectory : util.py . This file will run the trajectory during evaluation. After evaluation : save the trajectory : evaluate.py . This file will save the trajectory.","title":"overview"},{"location":"dev_docs/problem/","text":"problems.py This file stores the problems (a.k.a. objective function or optimizee) that you want LOIS to train or evaluate. Every problem should be in a format of function. Typically the function has two arguments: num_dims : The dimension of the problem. mode : A str indicates whether the problem is used during training or testing. This file is called by the function get_config in util.py . You need to add this function in get_config as well following the template there. An example of a problem is Rastrigin (square_cos): def square_cos(num_dims=2, mode='train'): def build(): \"\"\"Builds loss graph.\"\"\" batch_size=128 stddev=0.01 dtype=tf.float32 if mode=='test': x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(-3, 3)) return ( tf.reduce_sum(x*x - 10*tf.math.cos(2*3.1415926*x), 1)+ 10*num_dims ) # Trainable variable. x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(-3, 3)) # Non-trainable variables. w = tf.get_variable(\"w\", dtype=dtype, initializer=indentity_init(batch_size, num_dims, stddev/num_dims), trainable=False) y = tf.get_variable(\"y\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(stddev=stddev/num_dims), trainable=False) wcos = tf.get_variable(\"wcos\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(mean=1.0, stddev=stddev/num_dims), trainable=False) product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1))) product2 = tf.reduce_sum(wcos*10*tf.math.cos(2*3.1415926*x), 1) return (tf.reduce_sum((product - y) ** 2, 1)) - tf.reduce_mean(product2) + 10*num_dims return build Its caller in get_config function is: elif \"square_cos\" in problem_name: num_dims = int(problem_name.split('_')[-1]) problem = problems.square_cos(batch_size=128, num_dims=num_dims, mode=mode) net_config = {\"cw\": { \"net\": \"CoordinateWiseDeepLSTM\", \"net_options\": {\"layers\": (20, 20)}, \"net_path\": get_net_path(\"cw\", path) }} net_assignments = None","title":"problems.py"},{"location":"dev_docs/problem/#problemspy","text":"This file stores the problems (a.k.a. objective function or optimizee) that you want LOIS to train or evaluate. Every problem should be in a format of function. Typically the function has two arguments: num_dims : The dimension of the problem. mode : A str indicates whether the problem is used during training or testing. This file is called by the function get_config in util.py . You need to add this function in get_config as well following the template there. An example of a problem is Rastrigin (square_cos): def square_cos(num_dims=2, mode='train'): def build(): \"\"\"Builds loss graph.\"\"\" batch_size=128 stddev=0.01 dtype=tf.float32 if mode=='test': x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(-3, 3)) return ( tf.reduce_sum(x*x - 10*tf.math.cos(2*3.1415926*x), 1)+ 10*num_dims ) # Trainable variable. x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(-3, 3)) # Non-trainable variables. w = tf.get_variable(\"w\", dtype=dtype, initializer=indentity_init(batch_size, num_dims, stddev/num_dims), trainable=False) y = tf.get_variable(\"y\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(stddev=stddev/num_dims), trainable=False) wcos = tf.get_variable(\"wcos\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(mean=1.0, stddev=stddev/num_dims), trainable=False) product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1))) product2 = tf.reduce_sum(wcos*10*tf.math.cos(2*3.1415926*x), 1) return (tf.reduce_sum((product - y) ** 2, 1)) - tf.reduce_mean(product2) + 10*num_dims return build Its caller in get_config function is: elif \"square_cos\" in problem_name: num_dims = int(problem_name.split('_')[-1]) problem = problems.square_cos(batch_size=128, num_dims=num_dims, mode=mode) net_config = {\"cw\": { \"net\": \"CoordinateWiseDeepLSTM\", \"net_options\": {\"layers\": (20, 20)}, \"net_path\": get_net_path(\"cw\", path) }} net_assignments = None","title":"problems.py"},{"location":"dev_docs/train/","text":"train.py The main function for training LOIS. python train.py --problem=$problem_name --save_path=$path_to_the_saved_model Arugments: problem : The name of the training problem. save_path : The path to the saved model.","title":"train.py"},{"location":"dev_docs/train/#trainpy","text":"The main function for training LOIS. python train.py --problem=$problem_name --save_path=$path_to_the_saved_model Arugments: problem : The name of the training problem. save_path : The path to the saved model.","title":"train.py"},{"location":"dev_docs/utils/","text":"util.py This file has two main usages: * To run every eporch for training or evaluation * To get problem config. Run epoch run_epoch(sess, cost_op, ops, reset, num_unrolls, var1, var2) The training function for training the optimizer for one epoch. Arguments: sess : The tensorflow session variable. cost_op : The variable for training the optimzier. ops : A list = [variable for training the optimizer, the variable for optimization step]. reset : The initialization variable for initializing the optimizee before every epoch. num_unrolls : The number of unrolled RNNs. var1 : The tensor for the constants in the optimizee. var2 : The variable for optimizer parameters. Return: The running time The objective function values in this epoch. eval_run_epoch(sess, cost_op, ops, reset, num_unrolls, var1, var2) The evaluation function for optimizing the objective function using the optimizer for one epoch. Arguments: sess : The tensorflow session variable. cost_op : The variable for training the optimzier. ops : A list = [the variable for optimization step]. reset : The initialization variable for initializing the optimizee before every epoch. num_unrolls : The number of unrolled RNNs. var1 : The tensor for the constants in the optimizee. var2 : The variable for optimizer parameters. Return: The running time The objective function values in this epoch. Get problem config get_config(problem_name, path=None, mode='train') The function for obtaining the config of the problem and the optimizer Arguments: problem_name : The name of the problem. path : The path to the saved optimizer. During training it is None, during evaluation it is set to be the saved optimizer. mode : A string variable which should be set to 'train' during training and 'test' during evaluation. Return: problem : The call for the problem (a.k.a objective function/optimizee) net_config : A directory stores the configuration of the optmizer network. net_assignment : The assignment for the optimizer network.","title":"util.py"},{"location":"dev_docs/utils/#utilpy","text":"This file has two main usages: * To run every eporch for training or evaluation * To get problem config.","title":"util.py"},{"location":"dev_docs/utils/#run-epoch","text":"run_epoch(sess, cost_op, ops, reset, num_unrolls, var1, var2) The training function for training the optimizer for one epoch. Arguments: sess : The tensorflow session variable. cost_op : The variable for training the optimzier. ops : A list = [variable for training the optimizer, the variable for optimization step]. reset : The initialization variable for initializing the optimizee before every epoch. num_unrolls : The number of unrolled RNNs. var1 : The tensor for the constants in the optimizee. var2 : The variable for optimizer parameters. Return: The running time The objective function values in this epoch. eval_run_epoch(sess, cost_op, ops, reset, num_unrolls, var1, var2) The evaluation function for optimizing the objective function using the optimizer for one epoch. Arguments: sess : The tensorflow session variable. cost_op : The variable for training the optimzier. ops : A list = [the variable for optimization step]. reset : The initialization variable for initializing the optimizee before every epoch. num_unrolls : The number of unrolled RNNs. var1 : The tensor for the constants in the optimizee. var2 : The variable for optimizer parameters. Return: The running time The objective function values in this epoch.","title":"Run epoch"},{"location":"dev_docs/utils/#get-problem-config","text":"get_config(problem_name, path=None, mode='train') The function for obtaining the config of the problem and the optimizer Arguments: problem_name : The name of the problem. path : The path to the saved optimizer. During training it is None, during evaluation it is set to be the saved optimizer. mode : A string variable which should be set to 'train' during training and 'test' during evaluation. Return: problem : The call for the problem (a.k.a objective function/optimizee) net_config : A directory stores the configuration of the optmizer network. net_assignment : The assignment for the optimizer network.","title":"Get problem config"},{"location":"user_docs/eval/","text":"Evaluate your optimizer In order to evaluate your optimizer, you can run: python evaluate.py --problem=$problem_name --optimizer=L2L --path=$path_to_the_saved_model where $problem_name is the name of your problem; --optimizer gives the name of the optimizer and --path is the path to your trained model. For instance, in order to evalute a 2D Rastrigin function, you can set --problem=square_cos_2d and --path=../trained_models/square_cos_2/ .","title":"Evaluation"},{"location":"user_docs/eval/#evaluate-your-optimizer","text":"In order to evaluate your optimizer, you can run: python evaluate.py --problem=$problem_name --optimizer=L2L --path=$path_to_the_saved_model where $problem_name is the name of your problem; --optimizer gives the name of the optimizer and --path is the path to your trained model. For instance, in order to evalute a 2D Rastrigin function, you can set --problem=square_cos_2d and --path=../trained_models/square_cos_2/ .","title":"Evaluate your optimizer"},{"location":"user_docs/func/","text":"Add your function In order to add your functions for either training or evaluation, you should first navigate to the file src/problems.py and provide your function like the following example: def quadratic(batch_size=128, num_dims=10, stddev=0.01, dtype=tf.float32): \"\"\"Quadratic problem: f(x) = ||Wx - y||.\"\"\" def build(): \"\"\"Builds loss graph.\"\"\" # Trainable variable. x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(stddev=stddev)) w = tf.get_variable(\"w\", shape=[batch_size, num_dims, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(), trainable=False) y = tf.get_variable(\"y\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(), trainable=False) print(y.get_shape()) product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1))) return (tf.reduce_sum((product - y) ** 2, 1)) return build The above example creates a quadratic function f(x) = ||Wx - y||, where W and y are sampled from normal distributions.","title":"Add your function"},{"location":"user_docs/func/#add-your-function","text":"In order to add your functions for either training or evaluation, you should first navigate to the file src/problems.py and provide your function like the following example: def quadratic(batch_size=128, num_dims=10, stddev=0.01, dtype=tf.float32): \"\"\"Quadratic problem: f(x) = ||Wx - y||.\"\"\" def build(): \"\"\"Builds loss graph.\"\"\" # Trainable variable. x = tf.get_variable( \"x\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_normal_initializer(stddev=stddev)) w = tf.get_variable(\"w\", shape=[batch_size, num_dims, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(), trainable=False) y = tf.get_variable(\"y\", shape=[batch_size, num_dims], dtype=dtype, initializer=tf.random_uniform_initializer(), trainable=False) print(y.get_shape()) product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1))) return (tf.reduce_sum((product - y) ** 2, 1)) return build The above example creates a quadratic function f(x) = ||Wx - y||, where W and y are sampled from normal distributions.","title":"Add your function"},{"location":"user_docs/train/","text":"Train your optimizer It is very simple to train your optimizer: python train.py --problem=$problem_name --save_path=$path_to_the_saved_model where $problem_name is the name of your problem (e.g. $problem_name=square_cos_2d ) and $path_to_the_saved_model is the path where your trained model will be saved (e.g. $path_to_the_saved_model=../trained_models/square_cos_2d ).","title":"Training"},{"location":"user_docs/train/#train-your-optimizer","text":"It is very simple to train your optimizer: python train.py --problem=$problem_name --save_path=$path_to_the_saved_model where $problem_name is the name of your problem (e.g. $problem_name=square_cos_2d ) and $path_to_the_saved_model is the path where your trained model will be saved (e.g. $path_to_the_saved_model=../trained_models/square_cos_2d ).","title":"Train your optimizer"}]}